# -*- coding: utf-8 -*-
"""Dharvin Copy of SDA - Assignment (Part A).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WZqCpq_MemvRrX149Z0T91tbgPe7BACj
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import os
from scipy.stats import chisquare

# Load the uploaded dataset
file_path = '/content/estat_tec00038_en.csv'
data = pd.read_csv(file_path)

# Display the first few rows of the dataset to understand its structure
display(data)
print("")

# Extract the target column and analyze its properties
target_column = 'OBS_VALUE'
obs_values = data[target_column]

# Check basic statistics and distribution
obs_values = pd.to_numeric(obs_values, errors='coerce')  # Ensure numeric values
obs_values.dropna(inplace=True)
value_stats = obs_values.describe()

# Check the range and first few values
value_range = (obs_values.min(), obs_values.max())
value_head = obs_values.head()
value_stats, value_range, value_head

# Step 1: Prepare and clean the dataset for analysis (focus on target column)
# Remove any negative or zero values, as Benford's Law applies to positive numbers only
cleaned_values = obs_values[obs_values > 0]

# Step 2: Extract leading digits from the cleaned values
def extract_leading_digit(value):
    return int(str(value)[0])

leading_digits = cleaned_values.apply(extract_leading_digit)

# Step 3: Calculate the observed distribution of leading digits
observed_counts = leading_digits.value_counts().sort_index()
observed_distribution = observed_counts / observed_counts.sum()

# Step 4: Compare observed distribution with Benford's Law
# Calculate Benford's Law expected probabilities
benford_probabilities = np.log10(1 + 1 / np.arange(1, 10))

# Step 5: Visualization: Plot observed vs. expected distribution
plt.figure(figsize=(10, 6))
plt.bar(observed_distribution.index, observed_distribution.values, width=0.4, label="Observed", align='center')
plt.bar(np.arange(1, 10) + 0.4, benford_probabilities, width=0.4, label="Benford's Law", align='center')
plt.xticks(np.arange(1, 10))
plt.xlabel("Leading Digit")
plt.ylabel("Proportion")
plt.title("Observed vs. Benford's Law Leading Digit Distribution")
plt.legend()
plt.show()

# Step 6: Perform chi-square goodness-of-fit test
# Scale Benford's probabilities to match observed counts
expected_counts = benford_probabilities * observed_counts.sum()
chi2_stat, p_value = chisquare(f_obs=observed_counts, f_exp=expected_counts)
print("")
print("Chi-square Statistic:", chi2_stat)
print("P-value:", p_value)

# Step 7: Calculate Z-scores to highlight significant deviations
z_scores = (observed_counts - expected_counts) / np.sqrt(expected_counts)

# Step 8: Create a table summarizing the results
summary_df = pd.DataFrame({
    "Leading Digit": np.arange(1, 10),
    "Observed Count": observed_counts,
    "Expected Count": expected_counts,
    "Observed Proportion": observed_distribution,
    "Benford Proportion": benford_probabilities,
    "Difference (%)": (observed_distribution - benford_probabilities) * 100,
    "Z-score": z_scores
})
summary_df.fillna(0, inplace=True)  # Handle any NaN values
display(summary_df)

# Step 9: Plot cumulative distribution comparison
plt.figure(figsize=(10, 6))
plt.plot(np.arange(1, 10), observed_distribution.cumsum(), marker='o', label="Observed CDF")
plt.plot(np.arange(1, 10), benford_probabilities.cumsum(), marker='s', label="Benford's CDF")
plt.xlabel("Leading Digit")
plt.ylabel("Cumulative Proportion")
plt.title("Cumulative Distribution: Observed vs. Benford's Law")
plt.legend()
plt.grid()
plt.show()

